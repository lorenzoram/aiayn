{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aiayn - Attention is all you Need\n",
    "![alt text](images/aiayn/aiayn.png \"Architecture of AIAYN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "Since our model contains no recurrence and no convolution, in order for the model to make use of the\n",
    "order of the sequence, we must inject some information about the relative or absolute position of the\n",
    "tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\n",
    "bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\n",
    "as the embeddings, so that the two can be summed. There are many choices of positional encodings,\n",
    "learned and fixed [8].\n",
    "In this work, we use sine and cosine functions of different frequencies:\n",
    "P E(pos,2i) = sin(pos/100002i/dmodel)\n",
    "P E(pos,2i+1) = cos(pos/100002i/dmodel)\n",
    "\n",
    "where pos is the position and i is the dimension. That is, each dimension of the positional encoding\n",
    "corresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\n",
    "chose this function because we hypothesized it would allow the model to easily learn to attend by\n",
    "relative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\n",
    "P Epos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positional_encoding(length: int, depth: int) -> torch.Tensor:\n",
    "    depth = depth // 2\n",
    "    positions = torch.arange(length, dtype=torch.float32).unsqueeze(1)  # (seq, 1)\n",
    "    depths = torch.arange(depth, dtype=torch.float32).unsqueeze(0) / depth  # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000 ** depths)  # (1, depth)\n",
    "    angle_rads = positions * angle_rates  # (pos, depth)\n",
    "\n",
    "    pos_encoding = torch.cat((torch.sin(angle_rads), torch.cos(angle_rads)), dim=-1)  # (pos, depth*2)\n",
    "    return pos_encoding\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        length = x.size(1)\n",
    "        x = self.embedding(x)\n",
    "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        x = x + self.pos_encoding[:length, :].unsqueeze(0).to(x.device)\n",
    "        return x\n",
    "    \n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        # Implement this if needed\n",
    "        # TODO: Implement this\n",
    "        pass\n",
    "\n",
    "class CommonAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, **kwargs):\n",
    "        super(CommonAttention, self).__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim, num_heads, **kwargs)\n",
    "        self.layernorm = nn.LayerNorm(embed_dim)\n",
    "        self.add = nn.Identity()\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        attn_output, _ = self.mha(query, key, value, **kwargs)\n",
    "        output = self.add(query + attn_output)\n",
    "        output = self.layernorm(output)\n",
    "        return output\n",
    "    \n",
    "class CrossAttention(CommonAttention):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, **kwargs):\n",
    "        super(CrossAttention, self).__init__(embed_dim, num_heads, **kwargs)\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor, context: torch.Tensor) -> torch.Tensor:\n",
    "        attn_output, attn_scores = self.mha(query=x, key=context, value=context, need_weights=True)\n",
    "        self.last_attn_scores = attn_scores\n",
    "        x = x + attn_output\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "    \n",
    "class GlobalSelfAttention(CommonAttention):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, **kwargs):\n",
    "        super(GlobalSelfAttention, self).__init__(embed_dim, num_heads, **kwargs)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        attn_output, _ = self.mha(query=x, key=x, value=x)\n",
    "        x = x + attn_output\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "    \n",
    "class CausalSelfAttention(CommonAttention):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, **kwargs):\n",
    "        self.num_heads = num_heads\n",
    "        super(CausalSelfAttention, self).__init__(embed_dim, num_heads, **kwargs)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        attn_mask = torch.tril(torch.ones((seq_len, seq_len), device=x.device)).unsqueeze(0).unsqueeze(0)\n",
    "        attn_mask = attn_mask.expand(batch_size * self.num_heads, seq_len, seq_len)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 0, float('-inf')).masked_fill(attn_mask == 1, float(0.0))\n",
    "        attn_output, _ = self.mha(query=x, key=x, value=x, attn_mask=attn_mask)\n",
    "        x = x + attn_output\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, dff: int, dropout_rate: float = 0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(d_model, dff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dff, d_model),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.seq(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, *, d_model: int, num_heads: int, dff: int, dropout_rate: float = 0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attention = GlobalSelfAttention(embed_dim=d_model, num_heads=num_heads, dropout=dropout_rate)\n",
    "        self.ffn = FeedForward(d_model, dff, dropout_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, *, num_layers: int, d_model: int, num_heads: int,\n",
    "                 dff: int, vocab_size: int, dropout_rate: float = 0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        return x\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, *, d_model: int, num_heads: int, dff: int, dropout_rate: float = 0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.causal_self_attention = CausalSelfAttention(embed_dim=d_model, num_heads=num_heads, dropout=dropout_rate)\n",
    "        self.cross_attention = CrossAttention(embed_dim=d_model, num_heads=num_heads, dropout=dropout_rate)\n",
    "        self.ffn = FeedForward(d_model, dff, dropout_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, context: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.causal_self_attention(x)\n",
    "        x = self.cross_attention(x, context)\n",
    "        self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, *, num_layers: int, d_model: int, num_heads: int, dff: int, vocab_size: int, dropout_rate: float = 0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor, context: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, context)\n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "        return x\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, *, num_layers: int, d_model: int, num_heads: int, dff: int,\n",
    "                 input_vocab_size: int, target_vocab_size: int, dropout_rate: float = 0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
    "                               dff=dff, vocab_size=input_vocab_size, dropout_rate=dropout_rate)\n",
    "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
    "                               dff=dff, vocab_size=target_vocab_size, dropout_rate=dropout_rate)\n",
    "        self.final_layer = nn.Linear(d_model, target_vocab_size)\n",
    "\n",
    "    def forward(self, inputs: tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:\n",
    "        context, x = inputs\n",
    "        context = self.encoder(context)\n",
    "        x = self.decoder(x, context)\n",
    "        logits = self.final_layer(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will now prepare the data. We have found the [dataset](https://www.kaggle.com/datasets/tejasurya/eng-spanish) in [Kaggle](https://www.kaggle.com/), and it consists of 139,013 instances of translations from English to Spanish. The data preprocessing will include taking out the column \"metadata\", keeping only \"input\" and \"output\", as well as dropping duplicates and NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spa.csv', delimiter='\\t', header=None, names=['input', 'output', 'metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input   output                                           metadata\n",
       "0   Go.      Ve.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1   Go.    Vete.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2   Go.    Vaya.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3   Go.  Váyase.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "4   Hi.    Hola.  CC-BY 2.0 (France) Attribution: tatoeba.org #5..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['input', 'output']]\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.dropna(subset=['input', 'output'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input   output\n",
       "0   Go.      Ve.\n",
       "1   Go.    Vete.\n",
       "2   Go.    Vaya.\n",
       "3   Go.  Váyase.\n",
       "4   Hi.    Hola."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence Lengths: Mean = 31.20, Min = 3, Max = 300\n",
      "Output Sequence Lengths: Mean = 32.57, Min = 3, Max = 332\n"
     ]
    }
   ],
   "source": [
    "# Calculate the length of each input and output sentence\n",
    "input_lengths = data['input'].apply(len)\n",
    "output_lengths = data['output'].apply(len)\n",
    "\n",
    "# Calculate statistics for input lengths\n",
    "input_mean_length = input_lengths.mean()\n",
    "input_min_length = input_lengths.min()\n",
    "input_max_length = input_lengths.max()\n",
    "\n",
    "# Calculate statistics for output lengths\n",
    "output_mean_length = output_lengths.mean()\n",
    "output_min_length = output_lengths.min()\n",
    "output_max_length = output_lengths.max()\n",
    "\n",
    "# Print the statistics\n",
    "print(f'Input Sequence Lengths: Mean = {input_mean_length:.2f}, Min = {input_min_length}, Max = {input_max_length}')\n",
    "print(f'Output Sequence Lengths: Mean = {output_mean_length:.2f}, Min = {output_min_length}, Max = {output_max_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use a tokenizer to convert the text data into numerical representations that the model can process. Specifically, we use the BERT tokenizer, which breaks down the text into smaller units called tokens and maps each token to a unique identifier. This step is crucial because machine learning models, including Transformers, operate on numerical data rather than raw text. After tokenization, we apply padding and truncation to ensure that all sequences have the same length. Padding adds extra tokens to shorter sequences, while truncation cuts off longer sequences to a specified maximum length. This uniformity in sequence length is important because it allows for efficient batch processing and ensures that all inputs to the model have a consistent shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenizer (using BERT tokenizer for simplicity)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize data\n",
    "data['input_ids'] = data['input'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "data['output_ids'] = data['output'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th Percentile of Input Lengths: 14.0\n",
      "90th Percentile of Output Lengths: 19.0\n",
      "95th Percentile of Input Lengths: 15.0\n",
      "95th Percentile of Output Lengths: 22.0\n",
      "Selected max_len for padding: 19\n"
     ]
    }
   ],
   "source": [
    "input_lengths = data['input_ids'].apply(len)\n",
    "output_lengths = data['output_ids'].apply(len)\n",
    "\n",
    "# Calculate percentiles\n",
    "input_90th_percentile = input_lengths.quantile(0.90)\n",
    "output_90th_percentile = output_lengths.quantile(0.90)\n",
    "input_95th_percentile = input_lengths.quantile(0.95)\n",
    "output_95th_percentile = output_lengths.quantile(0.95)\n",
    "\n",
    "print(f'90th Percentile of Input Lengths: {input_90th_percentile}')\n",
    "print(f'90th Percentile of Output Lengths: {output_90th_percentile}')\n",
    "print(f'95th Percentile of Input Lengths: {input_95th_percentile}')\n",
    "print(f'95th Percentile of Output Lengths: {output_95th_percentile}')\n",
    "\n",
    "# Set max_len based on 95th percentile (or 90th)\n",
    "max_len = int(max(input_90th_percentile, output_90th_percentile))\n",
    "print(f'Selected max_len for padding: {max_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad and truncate\n",
    "def pad_and_truncate(sequence, max_len):\n",
    "    if len(sequence) > max_len:\n",
    "        return sequence[:max_len]\n",
    "    return sequence + [0] * (max_len - len(sequence))\n",
    "\n",
    "data['input_ids'] = data['input_ids'].apply(lambda x: pad_and_truncate(x, max_len))\n",
    "data['output_ids'] = data['output_ids'].apply(lambda x: pad_and_truncate(x, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence Lengths: Mean = 10.05, Min = 4, Max = 84\n",
      "Output Sequence Lengths: Mean = 13.61, Min = 4, Max = 116\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics for input lengths\n",
    "input_mean_length = input_lengths.mean()\n",
    "input_min_length = input_lengths.min()\n",
    "input_max_length = input_lengths.max()\n",
    "\n",
    "# Calculate statistics for output lengths\n",
    "output_mean_length = output_lengths.mean()\n",
    "output_min_length = output_lengths.min()\n",
    "output_max_length = output_lengths.max()\n",
    "\n",
    "# Print the statistics\n",
    "print(f'Input Sequence Lengths: Mean = {input_mean_length:.2f}, Min = {input_min_length}, Max = {input_max_length}')\n",
    "print(f'Output Sequence Lengths: Mean = {output_mean_length:.2f}, Min = {output_min_length}, Max = {output_max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_sequence_lengths(input_lengths, output_lengths):\n",
    "    plt.figure(figsize=(8, 4))  # Smaller figure size\n",
    "\n",
    "    # Histogram outlines for input and output lengths\n",
    "    plt.hist(input_lengths, bins=20, color='blue', edgecolor='blue', histtype='step', linewidth=1.5, label='Input Lengths')\n",
    "    plt.hist(output_lengths, bins=20, color='green', edgecolor='green', histtype='step', linewidth=1.5, label='Output Lengths')\n",
    "\n",
    "    plt.title('Distribution of Sequence Lengths')\n",
    "    plt.xlabel('Sequence Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.xlim(0, 120)\n",
    "    plt.show()\n",
    "\n",
    "# Plot sequence lengths\n",
    "plot_sequence_lengths(input_lengths, output_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples of the preprocessed dataset:\n",
      "Input: We need Tom's support.\n",
      "Output: Necesitamos el apoyo de Tom.\n",
      "\n",
      "\n",
      "Input: I woke up early yesterday.\n",
      "Output: Me desperté temprano ayer.\n",
      "\n",
      "\n",
      "Input: This box won't fit in my suitcase.\n",
      "Output: Esta caja no entrará en mi maleta.\n",
      "\n",
      "\n",
      "Input: That's really not the same thing.\n",
      "Output: Eso no es realmente lo mismo.\n",
      "\n",
      "\n",
      "Input: My friend ought to have arrived here by now.\n",
      "Output: Mi amigo ya debería haber llegado.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_examples(data, show_tokens=False):\n",
    "    print(\"Some examples of the preprocessed dataset:\")\n",
    "\n",
    "    # Randomize examples\n",
    "    random_indices = np.random.choice(len(data), size=5, replace=False)\n",
    "    for i in random_indices:\n",
    "        print(f\"Input: {data['input'].iloc[i]}\")\n",
    "        if show_tokens:\n",
    "            print(f\"Input Tokens: {data['input_ids'].iloc[i]}\")\n",
    "        print(f\"Output: {data['output'].iloc[i]}\")\n",
    "        if show_tokens:\n",
    "            print(f\"Output Tokens: {data['output_ids'].iloc[i]}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Show examples with or without tokens\n",
    "display_examples(data, show_tokens=False)  # Set to True to show tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.df.iloc[idx]['input_ids'])\n",
    "        output_ids = torch.tensor(self.df.iloc[idx]['output_ids'])\n",
    "        return input_ids, output_ids\n",
    "\n",
    "dataset = TranslationDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence Lengths: Mean = 10.05, Min = 4, Max = 84\n",
      "Output Sequence Lengths: Mean = 13.61, Min = 4, Max = 116\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics for input lengths\n",
    "input_mean_length = input_lengths.mean()\n",
    "input_min_length = input_lengths.min()\n",
    "input_max_length = input_lengths.max()\n",
    "\n",
    "# Calculate statistics for output lengths\n",
    "output_mean_length = output_lengths.mean()\n",
    "output_min_length = output_lengths.min()\n",
    "output_max_length = output_lengths.max()\n",
    "\n",
    "# Print the statistics\n",
    "print(f'Input Sequence Lengths: Mean = {input_mean_length:.2f}, Min = {input_min_length}, Max = {input_max_length}')\n",
    "print(f'Output Sequence Lengths: Mean = {output_mean_length:.2f}, Min = {output_min_length}, Max = {output_max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lucus\\AppData\\Local\\Temp\\ipykernel_16060\\2471533189.py\", line 3, in <module>\n",
      "    model = Transformer(\n",
      "  File \"C:\\Users\\lucus\\AppData\\Local\\Temp\\ipykernel_16060\\3857625345.py\", line 167, in __init__\n",
      "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
      "  File \"C:\\Users\\lucus\\AppData\\Local\\Temp\\ipykernel_16060\\3857625345.py\", line 114, in __init__\n",
      "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
      "  File \"C:\\Users\\lucus\\AppData\\Local\\Temp\\ipykernel_16060\\3857625345.py\", line 16, in __init__\n",
      "    self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 145, in __init__\n",
      "    self.reset_parameters()\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 154, in reset_parameters\n",
      "    init.normal_(self.weight)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\init.py\", line 175, in normal_\n",
      "    return _no_grad_normal_(tensor, mean, std, generator)\n",
      "  File \"C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\init.py\", line 20, in _no_grad_normal_\n",
      "    return tensor.normal_(mean, std, generator=generator)\n",
      "C:\\Users\\lucus\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\init.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  return tensor.normal_(mean, std, generator=generator)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = Transformer(\n",
    "    num_layers=2,\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    dff=2048,\n",
    "    input_vocab_size=len(tokenizer.vocab),\n",
    "    target_vocab_size=len(tokenizer.vocab),\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[1, 1, 18, 18]}, size=[256, 18, 18]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m---> 24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(batch, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      7\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# inputs and target sequences shifted for teacher forcing\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), targets[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 176\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    174\u001b[0m context, x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m    175\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(context)\n\u001b[1;32m--> 176\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(x)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 159\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, context)\u001b[0m\n\u001b[0;32m    157\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m--> 159\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attn_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlast_attn_scores\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 136\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[1;34m(self, x, context)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, context: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 136\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcausal_self_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention(x, context)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attn_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention\u001b[38;5;241m.\u001b[39mlast_attn_scores\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Cosas\\Universidad\\3.2\\Deep learning for NLP\\AIAYN\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 74\u001b[0m, in \u001b[0;36mCausalSelfAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m batch_size, seq_len, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m     73\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtril(torch\u001b[38;5;241m.\u001b[39mones((seq_len, seq_len), device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m \u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39mmasked_fill(attn_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mmasked_fill(attn_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m0.0\u001b[39m))\n\u001b[0;32m     76\u001b[0m attn_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmha(query\u001b[38;5;241m=\u001b[39mx, key\u001b[38;5;241m=\u001b[39mx, value\u001b[38;5;241m=\u001b[39mx, attn_mask\u001b[38;5;241m=\u001b[39mattn_mask)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[1, 1, 18, 18]}, size=[256, 18, 18]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "def train_step(batch, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    targets = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model((inputs, targets[:, :-1]))  # inputs and target sequences shifted for teacher forcing\n",
    "    loss = criterion(output.view(-1, output.size(-1)), targets[:, 1:].contiguous().view(-1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(10):  # 10 epochs for example\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        loss = train_step(batch, model, criterion, optimizer)\n",
    "        total_loss += loss\n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
